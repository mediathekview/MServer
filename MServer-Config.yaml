#### Server configurations ####

# The maximum amount of cpu threads to be used.
maximumCpuThreads: 10

# The maximum duration in minutes the server should run.<br>
# If set to 0 the server runs without a time limit.
maximumServerDurationInMinutes: 0

# Rate limiter
maximumRequestsPerSecond: 999.0

# These Sender will NOT be crawled.
# If no Sender are included the server will crawl all Sender but these.
#senderExcluded:
#  - ARD

# If set only these Sender will be crawled all other will be ignored.
senderIncluded:
  #- MDR
  #- NDR
  #- KIKA
  - DW
  #- BR
  #- PHOENIX

# If set the server will be awake after the crawler run and restarts the run after the given amount.
#schedules:
#   HalfDay:
#        duration: 12
#        unit: HOURS

# list of films to be ignored by crawler search
ignoreFilmlistPath: "ignoreFilmlist.txt"

# list of livestreams to be added
importLivestreamConfiguration: 
  active: false
  path: "live-streams.json"
  format: OLD_JSON

# The formats in which the filmlist should be saved to.
# Possible are: JSON, OLD_JSON, JSON_COMPRESSED_XZ, OLD_JSON_COMPRESSED_XZ, JSON_COMPRESSED_GZIP, OLD_JSON_COMPRESSED_BZIP, JSON_COMPRESSED_GZIP, OLD_JSON_COMPRESSED_BZIP
filmlistSaveFormats:
  - JSON
  - OLD_JSON
#  - JSON_COMPRESSED_XZ
#  - OLD_JSON_COMPRESSED_XZ
#  - JSON_COMPRESSED_GZIP
#  - OLD_JSON_COMPRESSED_GZIP
#  - JSON_COMPRESSED_BZIP
#  - OLD_JSON_COMPRESSED_BZIP

# The paths where which filmlist should be safed to.
filmlistSavePaths:
  JSON: target/filmlists/filmliste.json
  OLD_JSON: target/filmlists/filmliste_old.json
#  JSON_COMPRESSED_XZ: target/filmlists/filmliste.json.xz
#  OLD_JSON_COMPRESSED_XZ: target/filmlists/filmliste_old.json.xz
#  JSON_COMPRESSED_GZIP: target/filmlists/filmliste.json.gz
#  OLD_JSON_COMPRESSED_GZIP: target/filmlists/filmliste_old.json.gz
#  JSON_COMPRESSED_BZIP: target/filmlists/filmliste.json.bz
#  OLD_JSON_COMPRESSED_BZIP: target/filmlists/filmliste_old.json.bz

# The paths where which diff film list should be safed to.
# If not set no difference film lists will be safed.
filmlistDiffSavePaths:
  JSON: target/filmlists/filmliste_diff.json
  OLD_JSON: target/filmlists/filmliste_old_diff.json
#  JSON_COMPRESSED_XZ: target/filmlists/filmliste_diff.json.xz
#  OLD_JSON_COMPRESSED_XZ: target/filmlists/filmliste_old_diff.json.xz
#  JSON_COMPRESSED_GZIP: target/filmlists/filmliste_diff.json.gz
#  OLD_JSON_COMPRESSED_GZIP: target/filmlists/filmliste_old_diff.json.gz
#  JSON_COMPRESSED_BZIP: target/filmlists/filmliste_diff.json.bz
#  OLD_JSON_COMPRESSED_BZIP: target/filmlists/filmliste_old_diff.json.bz

#Sets if a filmlist hash file should be written
writeFilmlistHashFileEnabled: true
#The filmlist hash file path
filmlistHashFilePath: target/filmlists/filmlist.hash.xx

#Sets if a filmlist id file should be written
writeFilmlistIdFileEnabled: true
#The fimlist id file path
filmlistIdFilePath: target/filmlists/filmlist.id.xx


# import additional filmlist sources
importFilmlistConfigurations :
    - active: false
      path: "someCrawlerlist.json"
      format: OLD_JSON
      createDiff: false
      checkImportListUrl: false
    - active: false
      path: "someMoreCrawlerlist.json"
      format: OLD_JSON
      createDiff: false
      checkImportListUrl: false
    - active: false
      path: "https://verteiler1.mediathekview.de/filme-org.xz"
      format: OLD_JSON_COMPRESSED_XZ
      createDiff: true
      checkImportListUrl: true    

# film url is consider invalid if the size is below the minSize
checkImportListUrlMinSize: 5012

# abort url checking after x sec
checkImportListUrlTimeoutInSec: 1800

#### Default crawler configurations ####
# The maximum amount of URLs to be processed per task.
maximumUrlsPerTask: 50

# The maximum duration in minutes a crawler may run.
maximumCrawlDurationInMinutes: 120

# Enables the topics search
# maximumSubpages limits the depth of the topics search
topicsSearchEnabled: false

# The maximum amount of sub pages to be crawled.<br>
# Example: If a Sendung overview side has 10 pages with videos for this Sendung and
# the amount set by this is 5 then the crawler crawls pages 1 to 5.
maximumSubpages: 1

# The maximum amount of days going to past will be crawled for the "Sendung Verpasst?" section.
maximumDaysForSendungVerpasstSection: 7

# The maximum amount of days going to future will be crawled for the "Sendung Verpasst?" section.
maximumDaysForSendungVerpasstSectionFuture: 0

# The time in seconds before a socket connection should time out.
socketTimeoutInSeconds: 60


#### Specific crawler configurations ####
senderConfigurations:
  ARD:
    # Actually the ARD has a maximum of 6 days in the past
    maximumDaysForSendungVerpasstSection: 1
    #2,4,8 ok
    maximumUrlsPerTask: 32
    #10,20,40 ok
    maximumSubpages: 0
  ORF:
    #2,4,8 ok
    maximumUrlsPerTask: 40
  ARTE_DE:
    maximumUrlsPerTask: 1
    maximumDaysForSendungVerpasstSectionFuture: 0
    maximumRequestsPerSecond: 2.0
  ARTE_FR:
    maximumDaysForSendungVerpasstSectionFuture: 0
    # The maximum amount of URLs to be processed per task.
    #        maximumUrlsPerTask: 25
    # The maximum duration in minutes a crawler may run.
    #          maximumCrawlDurationInMinutes: 30
    # The maximum amount of sub pages to be crawled.<br>
    # Example: If a Sendung overview side has 10 pages with videos for this Sendung and
    # the amount set by this is 5 then the crawler crawls pages 1 to 5.
  #          maximumSubpages: 3
  KIKA:
    maximumSubpages: 2
    maximumRequestsPerSecond: 8.0
  SR:
    maximumRequestsPerSecond: 2.0
  ZDF:
    maximumRequestsPerSecond: 10.0
  FUNK:
    maximumUrlsPerTask: 99
  DW:
    maximumSubpages: 0

# configure string variables
crawlerApiParams:
  FUNK_REQUEST_TOKEN: 137782e774d7cadc93dcbffbbde0ce9c
  
#### COPY ####
copySettings:
  # En- / disables FTP
  copyEnabled: false

  # The paths where to safe the film list files.SrfTopicOverviewTask
  # WARNING: You can only set the path for film list formats you listed in "filmlistSaveFormats".
  # Required if enabled
  copyTargetFilePaths:
    # JSON: /var/www/mediathekview/filmlisten/filmliste.json
    OLD_JSON: copyTarget/filmliste_old.json
    # JSON_COMPRESSED: /var/www/mediathekview/filmlisten/filmliste.json.xz
    OLD_JSON_COMPRESSED_XZ: copyTarget/filmliste_old.json.xz

  copyTargetDiffFilePaths:
    # JSON: /var/www/mediathekview/filmlisten/filmliste_diff.json
    OLD_JSON: copyTarget/filmliste_old_diff.json
    # JSON_COMPRESSED: /var/www/mediathekview/filmlisten/filmliste_diff.json.xz
    OLD_JSON_COMPRESSED_XZ: copyTarget/filmliste_old_diff.json.xz

#### Logging ####
logSettings:
  # The log level for the console.
  # Can be: DEBUG, INFO, WARN, ERROR, FATAL
  logLevelConsole: DEBUG

  # The log level for the log file.
  # Can be: DEBUG, INFO, WARN, ERROR, FATAL
  logLevelFile: INFO

  # Should be logged to console?
  logActivateConsole: true

  # Should be logged to file?
  logActivateFile: true

  # En- or disables the rolling file appender.
  # If enabled the rolling file appender creates a new log file for every run.
  # See: https://logging.apache.org/log4j/2.0/manual/appenders.html#RollingFileAppender
  logActivateRollingFileAppend: true

  # The output pattern of the console log.
  # See: https://logging.apache.org/log4j/2.0/manual/layouts.html#PatternLayout
  logPatternConsole: "%d{HH:mm:ss.SSS} %highlight{%d [%t] %-5level: %msg%n%throwable}"

  # The output pattern of the file log.
  # See: https://logging.apache.org/log4j/2.0/manual/layouts.html#PatternLayout
  logPatternFile: "%d{HH:mm:ss.SSS} %d [%t] %-5level: %msg%n%throwable"

  # The path where the actual log file should be safed to.
  logFileSavePath: logs/server.log

  # The pattern of the file name of the archived log files.
  # See: https://logging.apache.org/log4j/2.0/manual/appenders.html#RollingFileAppender
  logFileRollingPattern: logs/${date:yyyy-MM}/server-%d{MM-dd-yyyy}-%i.log